{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0980ea7f-a582-4678-8a04-b56e760c3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6f589f-7d84-4b55-b467-d19f655fa11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                  ID  year  month  day  page  \\\n",
       "0              0  Koelnische_Zeitung.1870.04.20.08.6  1870      4   20     8   \n",
       "1              1  Koelnische_Zeitung.1870.12.20.07.2  1870     12   20     7   \n",
       "2              2  Koelnische_Zeitung.1870.08.24.05.3  1870      8   24     5   \n",
       "3              3  Koelnische_Zeitung.1870.05.27.04.5  1870      5   27     4   \n",
       "4              4  Koelnische_Zeitung.1870.04.01.04.2  1870      4    1     4   \n",
       "...          ...                                 ...   ...    ...  ...   ...   \n",
       "5863        5863  Koelnische_Zeitung.1870.01.08.04.1  1870      1    8     4   \n",
       "5864        5864  Koelnische_Zeitung.1870.10.18.02.3  1870     10   18     2   \n",
       "5865        5865  Koelnische_Zeitung.1870.04.18.03.4  1870      4   18     3   \n",
       "5866        5866  Koelnische_Zeitung.1870.08.18.02.4  1870      8   18     2   \n",
       "5867        5867  Koelnische_Zeitung.1870.02.14.02.2  1870      2   14     2   \n",
       "\n",
       "      number                                               text  \n",
       "0          6  euiter chandlung — bach, Drususgasse 18, en Em...  \n",
       "1          2  Tekegrapliiscie Depeschen.  Versailles, 19. De...  \n",
       "2          3  Kölner Loeal-Nachrichten. „ Köln, 24. Auguft. ...  \n",
       "3          5  „ Sur Nettung Schiffbrüchiger.  iil der alten ...  \n",
       "4          2  J. B. White & Brothers Perlland-Cement,  Jos.-...  \n",
       "...      ...                                                ...  \n",
       "5863       1  1. 9 — acftultl. Der Belu den Roateiken Ganens...  \n",
       "5864       3  Wachsamkeit der Nationalgarde daran berhindert...  \n",
       "5865       4  Lenser ind schon vor miehr als Jahresfrist an ...  \n",
       "5866       4  nur eine Strophe aus der Marfelllalse, gesunge...  \n",
       "5867       2  barkeit proclamirt ist, wird man in Rom finden...  \n",
       "\n",
       "[5868 rows x 8 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1870 = pd.read_csv(\"1870.csv\", sep=\";\")\n",
    "df1870.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7d327f-34cc-4758-9926-adddc5098d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                  ID  year  month  day  page  \\\n",
       "0              0  Koelnische_Zeitung.1871.12.17.02.2  1871     12   17     2   \n",
       "1              1  Koelnische_Zeitung.1871.01.16.06.3  1871      1   16     6   \n",
       "2              2  Koelnische_Zeitung.1871.10.13.06.4  1871     10   13     6   \n",
       "3              3  Koelnische_Zeitung.1871.03.29.08.1  1871      3   29     8   \n",
       "4              4  Koelnische_Zeitung.1871.12.26.06.1  1871     12   26     6   \n",
       "...          ...                                 ...   ...    ...  ...   ...   \n",
       "6009        6009  Koelnische_Zeitung.1871.01.06.04.2  1871      1    6     4   \n",
       "6010        6010  Koelnische_Zeitung.1871.12.07.03.4  1871     12    7     3   \n",
       "6011        6011  Koelnische_Zeitung.1871.08.07.04.2  1871      8    7     4   \n",
       "6012        6012  Koelnische_Zeitung.1871.03.10.03.5  1871      3   10     3   \n",
       "6013        6013  Koelnische_Zeitung.1871.11.22.09.4  1871     11   22     9   \n",
       "\n",
       "      number                                               text  \n",
       "0          2  eine ausreichende Beleuchtung durch Gas erbalt...  \n",
       "1          3  en Fothd) elnen schssüändizki eelrlcken Fanipl...  \n",
       "2          4  Vermischte Nachrichten. 1n  Dusseldorf, 10. Oe...  \n",
       "3          1  Uew--Yocker Germania.  Lebens-Versichernugs-Ge...  \n",
       "4          1  die ge- 0  don vielen Auderen. in deutscher We...  \n",
       "...      ...                                                ...  \n",
       "6009       2  Der derlschen El. Peserkburgü Zektund ist die ...  \n",
       "6010       4  Großbritanuien.  * London, 5. Det. Ora, Veust ...  \n",
       "6011       2  — . ö  .  t- — 3 1  3000SoScœœœoecœdoo 3 Ernte...  \n",
       "6012       5  Schulbücher-Verlag von J. Guttentag  as deer D...  \n",
       "6013       4  Schweiz. .  = Bern, 20. Nov. Heute hat der Nat...  \n",
       "\n",
       "[6014 rows x 8 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1871 = pd.read_csv(\"1871.csv\", sep=\";\")\n",
    "df1871.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4279903-abe5-47cd-ba4e-e3eaf91ff30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                  ID  year  month  day  page  \\\n",
       "0              0  Koelnische_Zeitung.1870.04.20.08.6  1870      4   20     8   \n",
       "1              1  Koelnische_Zeitung.1870.12.20.07.2  1870     12   20     7   \n",
       "2              2  Koelnische_Zeitung.1870.08.24.05.3  1870      8   24     5   \n",
       "3              3  Koelnische_Zeitung.1870.05.27.04.5  1870      5   27     4   \n",
       "4              4  Koelnische_Zeitung.1870.04.01.04.2  1870      4    1     4   \n",
       "...          ...                                 ...   ...    ...  ...   ...   \n",
       "6009        6009  Koelnische_Zeitung.1871.01.06.04.2  1871      1    6     4   \n",
       "6010        6010  Koelnische_Zeitung.1871.12.07.03.4  1871     12    7     3   \n",
       "6011        6011  Koelnische_Zeitung.1871.08.07.04.2  1871      8    7     4   \n",
       "6012        6012  Koelnische_Zeitung.1871.03.10.03.5  1871      3   10     3   \n",
       "6013        6013  Koelnische_Zeitung.1871.11.22.09.4  1871     11   22     9   \n",
       "\n",
       "      number                                               text  \n",
       "0          6  euiter chandlung — bach, Drususgasse 18, en Em...  \n",
       "1          2  Tekegrapliiscie Depeschen.  Versailles, 19. De...  \n",
       "2          3  Kölner Loeal-Nachrichten. „ Köln, 24. Auguft. ...  \n",
       "3          5  „ Sur Nettung Schiffbrüchiger.  iil der alten ...  \n",
       "4          2  J. B. White & Brothers Perlland-Cement,  Jos.-...  \n",
       "...      ...                                                ...  \n",
       "6009       2  Der derlschen El. Peserkburgü Zektund ist die ...  \n",
       "6010       4  Großbritanuien.  * London, 5. Det. Ora, Veust ...  \n",
       "6011       2  — . ö  .  t- — 3 1  3000SoScœœœoecœdoo 3 Ernte...  \n",
       "6012       5  Schulbücher-Verlag von J. Guttentag  as deer D...  \n",
       "6013       4  Schweiz. .  = Bern, 20. Nov. Heute hat der Nat...  \n",
       "\n",
       "[11882 rows x 8 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1870_1871 = pd.concat([df1870, df1871])\n",
    "df1870_1871.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741fa7a3-4ae6-482c-ac30-8b8db180753b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 24, 27,  1, 22, 17, 28, 19, 31,  5,  2,  3, 13, 23, 10, 15, 14,\n",
       "       16,  8,  9,  6, 11,  7, 26, 25, 18, 21, 30,  4, 29, 12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1870_1871['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a19820-aac8-4694-b02a-7e03b0f8533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40fd617b-957f-49f4-bf2a-bed0f6a0efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a44dc5-fa88-4873-b9d4-5d0ca6b6d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3548be09-605c-466b-a638-fa9b41509c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2c80cd-9be3-4edc-a7af-d56b005c888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2bd674b-9fe5-400d-9a98-ea520c17d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97cd823-55b6-496f-80c6-86b126dc3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ec05ba-83dc-4142-965c-7c2e05886b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b96deef5-6a36-438a-b7ec-0067fff21674",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('german')\n",
    "\n",
    "def stem(text):\n",
    "    return stemmer.stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc7d0449-2df9-4465-b242-e50abe3b1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text, min_len=4): \n",
    "        if token not in stopwords:\n",
    "            result.append(stem(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41dc64fe-2605-4563-b692-f89e688decc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                  ID  year  month  day  page  \\\n",
       "0              0  Koelnische_Zeitung.1870.04.20.08.6  1870      4   20     8   \n",
       "1              1  Koelnische_Zeitung.1870.12.20.07.2  1870     12   20     7   \n",
       "2              2  Koelnische_Zeitung.1870.08.24.05.3  1870      8   24     5   \n",
       "3              3  Koelnische_Zeitung.1870.05.27.04.5  1870      5   27     4   \n",
       "4              4  Koelnische_Zeitung.1870.04.01.04.2  1870      4    1     4   \n",
       "...          ...                                 ...   ...    ...  ...   ...   \n",
       "5863        5863  Koelnische_Zeitung.1870.01.08.04.1  1870      1    8     4   \n",
       "5864        5864  Koelnische_Zeitung.1870.10.18.02.3  1870     10   18     2   \n",
       "5865        5865  Koelnische_Zeitung.1870.04.18.03.4  1870      4   18     3   \n",
       "5866        5866  Koelnische_Zeitung.1870.08.18.02.4  1870      8   18     2   \n",
       "5867        5867  Koelnische_Zeitung.1870.02.14.02.2  1870      2   14     2   \n",
       "\n",
       "      number                                               text  \n",
       "0          6  euiter chandlung — bach, Drususgasse 18, en Em...  \n",
       "1          2  Tekegrapliiscie Depeschen.  Versailles, 19. De...  \n",
       "2          3  Kölner Loeal-Nachrichten. „ Köln, 24. Auguft. ...  \n",
       "3          5  „ Sur Nettung Schiffbrüchiger.  iil der alten ...  \n",
       "4          2  J. B. White & Brothers Perlland-Cement,  Jos.-...  \n",
       "...      ...                                                ...  \n",
       "5863       1  1. 9 — acftultl. Der Belu den Roateiken Ganens...  \n",
       "5864       3  Wachsamkeit der Nationalgarde daran berhindert...  \n",
       "5865       4  Lenser ind schon vor miehr als Jahresfrist an ...  \n",
       "5866       4  nur eine Strophe aus der Marfelllalse, gesunge...  \n",
       "5867       2  barkeit proclamirt ist, wird man in Rom finden...  \n",
       "\n",
       "[5868 rows x 8 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1870 = pd.read_csv(\"1870.csv\", sep=\";\")\n",
    "df1870.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24159a25-ca0c-4109-a43f-0a032f541a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                  ID  year  month  day  page  \\\n",
       "0              0  Koelnische_Zeitung.1871.12.17.02.2  1871     12   17     2   \n",
       "1              1  Koelnische_Zeitung.1871.01.16.06.3  1871      1   16     6   \n",
       "2              2  Koelnische_Zeitung.1871.10.13.06.4  1871     10   13     6   \n",
       "3              3  Koelnische_Zeitung.1871.03.29.08.1  1871      3   29     8   \n",
       "4              4  Koelnische_Zeitung.1871.12.26.06.1  1871     12   26     6   \n",
       "...          ...                                 ...   ...    ...  ...   ...   \n",
       "6009        6009  Koelnische_Zeitung.1871.01.06.04.2  1871      1    6     4   \n",
       "6010        6010  Koelnische_Zeitung.1871.12.07.03.4  1871     12    7     3   \n",
       "6011        6011  Koelnische_Zeitung.1871.08.07.04.2  1871      8    7     4   \n",
       "6012        6012  Koelnische_Zeitung.1871.03.10.03.5  1871      3   10     3   \n",
       "6013        6013  Koelnische_Zeitung.1871.11.22.09.4  1871     11   22     9   \n",
       "\n",
       "      number                                               text  \n",
       "0          2  eine ausreichende Beleuchtung durch Gas erbalt...  \n",
       "1          3  en Fothd) elnen schssüändizki eelrlcken Fanipl...  \n",
       "2          4  Vermischte Nachrichten. 1n  Dusseldorf, 10. Oe...  \n",
       "3          1  Uew--Yocker Germania.  Lebens-Versichernugs-Ge...  \n",
       "4          1  die ge- 0  don vielen Auderen. in deutscher We...  \n",
       "...      ...                                                ...  \n",
       "6009       2  Der derlschen El. Peserkburgü Zektund ist die ...  \n",
       "6010       4  Großbritanuien.  * London, 5. Det. Ora, Veust ...  \n",
       "6011       2  — . ö  .  t- — 3 1  3000SoScœœœoecœdoo 3 Ernte...  \n",
       "6012       5  Schulbücher-Verlag von J. Guttentag  as deer D...  \n",
       "6013       4  Schweiz. .  = Bern, 20. Nov. Heute hat der Nat...  \n",
       "\n",
       "[6014 rows x 8 columns]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1871 = pd.read_csv(\"1871.csv\", sep=\";\")\n",
    "df1871.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77248122-c3d3-4b45-918a-a4959f2cecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                  ID  year  month  day  page  \\\n",
       "0              0  Koelnische_Zeitung.1870.04.20.08.6  1870      4   20     8   \n",
       "1              1  Koelnische_Zeitung.1870.12.20.07.2  1870     12   20     7   \n",
       "2              2  Koelnische_Zeitung.1870.08.24.05.3  1870      8   24     5   \n",
       "3              3  Koelnische_Zeitung.1870.05.27.04.5  1870      5   27     4   \n",
       "4              4  Koelnische_Zeitung.1870.04.01.04.2  1870      4    1     4   \n",
       "...          ...                                 ...   ...    ...  ...   ...   \n",
       "6009        6009  Koelnische_Zeitung.1871.01.06.04.2  1871      1    6     4   \n",
       "6010        6010  Koelnische_Zeitung.1871.12.07.03.4  1871     12    7     3   \n",
       "6011        6011  Koelnische_Zeitung.1871.08.07.04.2  1871      8    7     4   \n",
       "6012        6012  Koelnische_Zeitung.1871.03.10.03.5  1871      3   10     3   \n",
       "6013        6013  Koelnische_Zeitung.1871.11.22.09.4  1871     11   22     9   \n",
       "\n",
       "      number                                               text  \n",
       "0          6  euiter chandlung — bach, Drususgasse 18, en Em...  \n",
       "1          2  Tekegrapliiscie Depeschen.  Versailles, 19. De...  \n",
       "2          3  Kölner Loeal-Nachrichten. „ Köln, 24. Auguft. ...  \n",
       "3          5  „ Sur Nettung Schiffbrüchiger.  iil der alten ...  \n",
       "4          2  J. B. White & Brothers Perlland-Cement,  Jos.-...  \n",
       "...      ...                                                ...  \n",
       "6009       2  Der derlschen El. Peserkburgü Zektund ist die ...  \n",
       "6010       4  Großbritanuien.  * London, 5. Det. Ora, Veust ...  \n",
       "6011       2  — . ö  .  t- — 3 1  3000SoScœœœoecœdoo 3 Ernte...  \n",
       "6012       5  Schulbücher-Verlag von J. Guttentag  as deer D...  \n",
       "6013       4  Schweiz. .  = Bern, 20. Nov. Heute hat der Nat...  \n",
       "\n",
       "[11882 rows x 8 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1870_1871 = pd.concat([df1870, df1871])\n",
    "df1870_1871.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc5abff3-c7ac-43c1-9a58-0d83a6726697",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = (df1870_1871['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee2c48fc-50dd-49e7-b340-75f633de79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1870_1871 = pd.concat([df1870, df1871])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3660b1ce-4e08-4975-b66a-8df38259b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # tqdm zeigt uns den Fortschritt eines loops an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "394759bc-8e18-47ba-9ef1-cd064a34d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11882/11882 [00:55<00:00, 214.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11882\n",
      "[['euit', 'chandlung', 'bach', 'drususgass', 'empfang', 'neu', 'mod', 'anzuleig', 'wasch', 'handlung', 'klein', 'sott', 'leim', 'gedild', 'jertig', 'itt', 'aeneiat', 'rufpruch', 'fillal', 'goln', 'jeit', 'lan', 'zeit', 'hab', 'rauch', 'fuhl', 'mich', 'verpflichtet', 'out', 'erfolg', 'eruelt', 'hab', 'verlé', 'nament', 'nerv', 'kopf', 'gesund', 'erhal', 'alulfeit', 'anertenn', 'wirt', 'forder', 'gabtenz', 'general', 'wien', 'teun', 'kopfst', 'oosgododcoog', 'iedaill', 'tienk', 'tiel', 'reronga', 'cent', 'siech', 'mittel', 'form', 'rodan', 'chwei', 'zubereitet', 'schafenstrass', 'cendaor', 'agunrtnghoft', 'eneeeek', 'llitzenghan', 'urgeheic', 'zuck', 'nicht', 'dunit', 'hal', 'auch', 'findet', 'dasetdit', 'lehrl', 'gehrlk', 'volontair', 'ziegelpfkng', 'wird', 'gesucht', 'sagt', 'markibuv', 'verk', 'alt', 'vach', 'aar', 'deen', 'luui', 'fucht', 'ofert', 'rdler', 'kesl', 'best', 'sort', 'drei', 'grof', 'maschbut', 'eenedenh', 'vean', 'neu', 'vadewann', 'handlung', 'institut', 'och', 'koln', 'rpostelnklost', 'zulahr', 'april', 'missenf', 'lcte', 'leueh', 'keh', 'fach', 'unt', 'brsond', 'alusichtnahm', 'freiwill', 'exam', 'bebrplan', 'bedinzuteg', 'anfnahm', 'ettern', 'penstonawr', 'zerseh', 'realschul', 'hoh', 'tochterschul', 'mulheim', 'ruhr', 'senesemes', 'aegiun', 'din', 'denred', 'deerz', 'aria', 'sted', 'dameniied', 'rnack', 'unenne', 'feerenc', 'vertau', 'leu', 'ohning', 'vedenaeif', 'gruhl', 'direttor', 'johanna', 'wing', 'unterricht', 'franz', 'auoftat', 'rntertieng', 'blig', 'zeilt', 'meniteid', 'nach', 'nerz', 'holl', 'sprach', 'lereb', 'llig', 'uni', 'zusicher', 'solid', 'bed', 'rntreiticdir', 'elemn', 'eer', 'mter', 'bresg', 'zahripulv', 'engr', 'wilhelustrass', 'uees', 'mian', 'doynung', 'vertegt', 'ehr', 'flaf', 'citron', 'indne', 'deeun', 'maiwoinndek', 'citron', 'imonada', 'asf', 'himbe', 'limonnd', 'past', 'baton', 'orn', 'palei', 'uiad', 'maitrank', 'imonad', 'paket', 'gros', 'angemes', 'dichat', 'empsehl', 'stonerd', 'eohn', 'specialité', 'pour', 'mod', 'arrongeè', 'soeur', 'minoritenstr', 'being', 'hiermit', 'reichhalt', 'ass', 'timent', 'einviem', 'fermeruma', 'costum', 'confecnol', 'derigt', 'nach', 'neu', 'franz', 'deut', 'gdurnal', 'weich', 'ansiti', 'lieg', 'alt', 'totay', 'trass', 'nach', 'vand', 'berucritra', 'ein', 'bstkottend', 'lafe', 'lur', 'oeeh', 'herniann', 'schmarack', 'breierass', 'nach', 'unt', 'beorai', 'scutzenverem', 'veoen', 'sub', 'derschkang', 'schir', 'voriepdé', 'gewetr', 'taichencero', 'weis', 'hos', 'sehr', 'girl', 'stand', 'verkauf', 'koln', 'herzo', 'witw', 'molitor', 'cuhneraug', 'eingewachfezt', 'ragel', 'overatcueln', 'rieit', 'dorn', 'jorlog', 'gart', 'lanf', 'saei', 'veftdeld', 'kochpsort', 'leop', 'geld', 'paris', 'sonnenschirm', 'gsautsend', 'kaeeie', 'ledn', 'ere', 'unt', 'besorot', 'hohleneck', 'planino', 'valiland', 'georg', 'delutra', 'leened', 'talir', 'fin', 'gross', 'drehmangel', 'viauinos', 'wilhelin', 'mies', 'verkack', 'grok', 'tcedraphendr', 'gedesb', 'ated', 'geementericcd', 'stulpstiefel', 'glanzled', 'erstungofaligo', 'fabelt', 'weln', 'verfauf', 'nonstraf', 'lenuaan', 'roanineedenn', 'dels', 'ihro', 'prois', 'couranic', 'untr', 'salz', 'waneo', 'sed', 'gadecb', 'salz', 'lefettvec', 'donweis', 'billig', 'vator', 'sucgelring', 'weiss', 'gaipd', 'kadr', 'train', 'rotl', 'stein', 'welch', 'wapr', 'eingeschnttt', 'egen', 'velol', 'ehrenfeld', 'koln', 'ugeb', 'teterttrai', 'verdeaux', 'silbern', 'hoppel', 'xorgneti', 'beke', 'vargersckas', 'oserionntag', 'fiora', 'verlor', 'kirich', 'euronenesc', 'ruasahrt', 'dork', 'seig', 'angem', 'urart', 'trolat', 'gehtted', 'leg', 'venck', 'euckt', 'reiwel', 'senz', 'nunz', 'abuutgeb', 'eiisenfirass', 'bowi', 'empr', 'scholiizdzcarr', 'shamt', 'neisss', 'bevchnann', 'bolzengass', 'eich', 'siageschiag', 'ein', 'vank', 'severtns', 'rommenad', 'lieg', 'geblieb', 'redi', 'find', 'wird', 'geb', 'jelb', 'wiederzug', 'lowengast', 'gold', 'ourr', 'frans', 'llor', 'gegan', 'wiederbring', 'belohnuna', 'ankauf', 'wird', 'leer', 'abiuged', 'krenzaass', 'bint', 'derl', 'sgeg', 'abzug', 'vantakeontr', 'ctnie', 'gold', 'zihriett', 'verl', 'wier', 'ebengererb', 'velchn', 'rhefnaust', 'mmig', 'sorallerikeli', 'fora', 'verlor', 'geg', 'velohnund', 'gbugeb', 'domstrass', 'eriemonnat', 'deror', 'abzug', 'stensadcrsals', 'laug', 'keulg', 'backfiich', 'alaisl', 'geit', 'khrist', 'mor', 'rbeingass', 'tarbot', 'seezung', 'scheufisit', 'cabliau', 'geraat', 'morn', 'frisch', 'vorzslalich', 'titt', 'tiumaan', 'ockel', 'ftes', 'ilsdek', 'ponrauol', 'teeret', 'remr', 'sel', 'enu', 'ein', 'brick', 'heus', 'nict', 'dekomn', 'dein', 'brief', 'vost', 'femtanto', 'vnen', 'vost', 'enen', 'dwet', 'nuchig', 'pund', 'entla', 'abend', 'buer', 'fiop', 'shmik', 'longcrich', 'prandent'], ['tekegrapliisci', 'depesch', 'versaill', 'offuciel', 'general', 'werd', 'griff', 'veind', 'welch', 'betracht', 'starl', 'nuil', 'pesm', 'sland', 'abend', 'nuit', 'genomnn', 'etwa', 'gefang', 'gemacht', 'wurd', 'sudlich', 'westlich', 'nichtung', 'verfolgt', 'diesseit', 'minz', 'wilhelm', 'bad', 'general', 'glum', 'leicht', 'verwundet', 'seit', 'corps', 'wurd', 'versolg', 'uber', 'epulsap', 'forigesetzt', 'traineur', 'gesang', 'genomm', 'ein', 'fahn', 'erbeuiet', 'and', 'abtheil', 'halt', 'poislag', 'font', 'dell', 'gefecht', 'geg', 'ein', 'elwa', 'mann', 'stark', 'feind', 'richtung', 'man', 'verfolgt', 'wird', 'colonn', 'link', 'flugel', 'sind', 'marsch', 'chtteau', 'renault', 'podbielsti', 'poislay', 'fontenell', 'wesllich', 'chateaudun', 'bertin', 'verhandl', 'geg', 'londesverrath', 'angellagt', 'gueterboc', 'kusp', 'meh', 'coar', 'leviita', 'sind', 'weg', 'ploklich', 'erkrani', 'guckerboc', 'weit', 'verlagt', 'stuttgart', 'nach', 'genau', 'verechn', 'wurd', 'enb', 'dudeehn', 'eieen', 'unm', 'eron', 'oder', 'vertrag', 'geg', 'denselb', 'sind', 'zweiselhaft', 'ohnag', 'heutig', 'sizung', 'zweit', 'kamm', 'raulasst', 'ein', 'kerst', 'gestelli', 'inderpellation', 'welilich', 'gewalt', 'papst', 'thun', 'soll', 'ein', 'lang', 'debatt', 'krieg', 'minisl', 'mull', 'welch', 'terimit', 'auch', 'ministerium', 'neuss', 'teitet', 'erllart', 'regi', 'tung', 'konn', 'dies', 'angeleg', 'nicht', 'intervenir', 'schliesslich', 'wurd', 'antrag', 'putt', 'kamm', 'mog', 'erllar', 'olland', 'hab', 'nicht', 'missi', 'schritt', 'kustich', 'gewalt', 'thun', 'geg', 'stimm', 'abgelehnt', 'geg', 'anlrag', 'cren', 'uebergang', 'tagesordn', 'geg', 'slimm', 'angenoina']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess - process all documents\n",
    "processed_docs = []\n",
    "for i in tqdm(range(0, len((df1870_1871['text'].tolist())))) :\n",
    "    processed_docs.append(preprocess((df1870_1871['text'].tolist()[i])))\n",
    "    \n",
    "print(len(processed_docs))\n",
    "\n",
    "print(processed_docs[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfdb6abb-7b2d-4793-8b80-31ea9fc3e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948133\n",
      "0 aar\n",
      "1 abend\n",
      "2 abiuged\n",
      "3 abuutgeb\n",
      "4 abzug\n",
      "5 aegiun\n",
      "6 aeneiat\n",
      "7 agunrtnghoft\n",
      "8 alaisl\n",
      "9 alt\n"
     ]
    }
   ],
   "source": [
    "# preprocess - convert word content into dictionary\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs) # erstellt ein dictionary, das jedem singulären Wort eine id zuordnet. Das dictionary enthält das Vokabular V des Korpus.\n",
    "print(len(dictionary)) # Größe des Vokabulars\n",
    "\n",
    "index = 0\n",
    "for key, value in dictionary.iteritems():\n",
    "    print(key, value)\n",
    "    index +=1\n",
    "    if index > 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d83f2785-0708-4d21-b590-d28584390ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11882/11882 [00:03<00:00, 3249.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 2), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 2), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 2), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 3), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 2), (82, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 1), (88, 1), (89, 1), (90, 3), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 2), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 2), (124, 1), (125, 2), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess - further dimensionality reduction\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n = 10000) # Funktion erlaubt es, sehr seltene und sehr häufige Wörter auszuschließen\n",
    "print(len(dictionary))\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in tqdm(processed_docs)] # konvertiert ein Dokument (Liste von Wörtern) in das bag-of-words Format = 2er-Tupel (token_id, token_count). \n",
    "print(bow_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0351d0f2-540f-4e61-9459-626a6f7aba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:00<00:00, 54430.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 0 = \"aar\": occurrences=1\n",
      "Key 1 = \"abend\": occurrences=1\n",
      "Key 2 = \"abzug\": occurrences=2\n",
      "Key 3 = \"alt\": occurrences=2\n",
      "Key 4 = \"ankauf\": occurrences=1\n",
      "Key 5 = \"april\": occurrences=1\n",
      "Key 6 = \"ass\": occurrences=1\n",
      "Key 7 = \"bach\": occurrences=1\n",
      "Key 8 = \"bed\": occurrences=1\n",
      "Key 9 = \"being\": occurrences=1\n",
      "Key 10 = \"best\": occurrences=1\n",
      "Key 11 = \"billig\": occurrences=1\n",
      "Key 12 = \"bint\": occurrences=1\n",
      "Key 13 = \"brief\": occurrences=1\n",
      "Key 14 = \"cent\": occurrences=1\n",
      "Key 15 = \"costum\": occurrences=1\n",
      "Key 16 = \"deen\": occurrences=1\n",
      "Key 17 = \"dein\": occurrences=1\n",
      "Key 18 = \"dels\": occurrences=1\n",
      "Key 19 = \"derl\": occurrences=1\n",
      "Key 20 = \"deut\": occurrences=1\n",
      "Key 21 = \"din\": occurrences=1\n",
      "Key 22 = \"dork\": occurrences=1\n",
      "Key 23 = \"dorn\": occurrences=1\n",
      "Key 24 = \"drei\": occurrences=1\n",
      "Key 25 = \"eer\": occurrences=1\n",
      "Key 26 = \"egen\": occurrences=1\n",
      "Key 27 = \"ehr\": occurrences=1\n",
      "Key 28 = \"eich\": occurrences=1\n",
      "Key 29 = \"empfang\": occurrences=1\n",
      "Key 30 = \"empsehl\": occurrences=1\n",
      "Key 31 = \"enen\": occurrences=1\n",
      "Key 32 = \"ere\": occurrences=1\n",
      "Key 33 = \"erfolg\": occurrences=1\n",
      "Key 34 = \"erhal\": occurrences=1\n",
      "Key 35 = \"exam\": occurrences=1\n",
      "Key 36 = \"fach\": occurrences=1\n",
      "Key 37 = \"fin\": occurrences=1\n",
      "Key 38 = \"find\": occurrences=1\n",
      "Key 39 = \"findet\": occurrences=1\n",
      "Key 40 = \"forder\": occurrences=1\n",
      "Key 41 = \"form\": occurrences=1\n",
      "Key 42 = \"franz\": occurrences=2\n",
      "Key 43 = \"freiwill\": occurrences=1\n",
      "Key 44 = \"frisch\": occurrences=1\n",
      "Key 45 = \"fucht\": occurrences=1\n",
      "Key 46 = \"fuhl\": occurrences=1\n",
      "Key 47 = \"gart\": occurrences=1\n",
      "Key 48 = \"geb\": occurrences=1\n",
      "Key 49 = \"geblieb\": occurrences=1\n",
      "Key 50 = \"geit\": occurrences=1\n",
      "Key 51 = \"geld\": occurrences=1\n",
      "Key 52 = \"general\": occurrences=1\n",
      "Key 53 = \"georg\": occurrences=1\n",
      "Key 54 = \"gesucht\": occurrences=1\n",
      "Key 55 = \"gesund\": occurrences=1\n",
      "Key 56 = \"gold\": occurrences=2\n",
      "Key 57 = \"goln\": occurrences=1\n",
      "Key 58 = \"grof\": occurrences=1\n",
      "Key 59 = \"grok\": occurrences=1\n",
      "Key 60 = \"gros\": occurrences=1\n",
      "Key 61 = \"hal\": occurrences=1\n",
      "Key 62 = \"handlung\": occurrences=2\n",
      "Key 63 = \"heus\": occurrences=1\n",
      "Key 64 = \"hiermit\": occurrences=1\n",
      "Key 65 = \"hoh\": occurrences=1\n",
      "Key 66 = \"holl\": occurrences=1\n",
      "Key 67 = \"hos\": occurrences=1\n",
      "Key 68 = \"institut\": occurrences=1\n",
      "Key 69 = \"itt\": occurrences=1\n",
      "Key 70 = \"jeit\": occurrences=1\n",
      "Key 71 = \"jelb\": occurrences=1\n",
      "Key 72 = \"jertig\": occurrences=1\n",
      "Key 73 = \"klein\": occurrences=1\n",
      "Key 74 = \"koln\": occurrences=3\n",
      "Key 75 = \"kopf\": occurrences=1\n",
      "Key 76 = \"lan\": occurrences=1\n",
      "Key 77 = \"laug\": occurrences=1\n",
      "Key 78 = \"leer\": occurrences=1\n",
      "Key 79 = \"leg\": occurrences=1\n",
      "Key 80 = \"leu\": occurrences=1\n",
      "Key 81 = \"lieg\": occurrences=2\n",
      "Key 82 = \"lur\": occurrences=1\n",
      "Key 83 = \"mian\": occurrences=1\n",
      "Key 84 = \"mich\": occurrences=1\n",
      "Key 85 = \"mittel\": occurrences=1\n",
      "Key 86 = \"mod\": occurrences=2\n",
      "Key 87 = \"mulheim\": occurrences=1\n",
      "Key 88 = \"nament\": occurrences=1\n",
      "Key 89 = \"nerv\": occurrences=1\n",
      "Key 90 = \"neu\": occurrences=3\n",
      "Key 91 = \"nict\": occurrences=1\n",
      "Key 92 = \"ofert\": occurrences=1\n",
      "Key 93 = \"paris\": occurrences=1\n",
      "Key 94 = \"pour\": occurrences=1\n",
      "Key 95 = \"rauch\": occurrences=1\n",
      "Key 96 = \"realschul\": occurrences=1\n",
      "Key 97 = \"reichhalt\": occurrences=1\n",
      "Key 98 = \"ruhr\": occurrences=1\n",
      "Key 99 = \"sagt\": occurrences=1\n",
      "Key 100 = \"salz\": occurrences=2\n",
      "Key 101 = \"sed\": occurrences=1\n",
      "Key 102 = \"sehr\": occurrences=1\n",
      "Key 103 = \"seig\": occurrences=1\n",
      "Key 104 = \"sel\": occurrences=1\n",
      "Key 105 = \"silbern\": occurrences=1\n",
      "Key 106 = \"solid\": occurrences=1\n",
      "Key 107 = \"sort\": occurrences=1\n",
      "Key 108 = \"sprach\": occurrences=1\n",
      "Key 109 = \"stand\": occurrences=1\n",
      "Key 110 = \"sted\": occurrences=1\n",
      "Key 111 = \"stein\": occurrences=1\n",
      "Key 112 = \"sub\": occurrences=1\n",
      "Key 113 = \"tiel\": occurrences=1\n",
      "Key 114 = \"train\": occurrences=1\n",
      "Key 115 = \"uni\": occurrences=1\n",
      "Key 116 = \"unterricht\": occurrences=1\n",
      "Key 117 = \"vach\": occurrences=1\n",
      "Key 118 = \"vand\": occurrences=1\n",
      "Key 119 = \"vank\": occurrences=1\n",
      "Key 120 = \"verk\": occurrences=1\n",
      "Key 121 = \"verkauf\": occurrences=1\n",
      "Key 122 = \"verl\": occurrences=1\n",
      "Key 123 = \"verlor\": occurrences=2\n",
      "Key 124 = \"verpflichtet\": occurrences=1\n",
      "Key 125 = \"vost\": occurrences=2\n",
      "Key 126 = \"wasch\": occurrences=1\n",
      "Key 127 = \"weich\": occurrences=1\n",
      "Key 128 = \"weis\": occurrences=1\n",
      "Key 129 = \"weiss\": occurrences=1\n",
      "Key 130 = \"wien\": occurrences=1\n",
      "Key 131 = \"wier\": occurrences=1\n",
      "Key 132 = \"wirt\": occurrences=1\n",
      "Key 133 = \"witw\": occurrences=1\n",
      "Key 134 = \"zeit\": occurrences=1\n",
      "Key 135 = \"zuck\": occurrences=1\n",
      "Key 136 = \"zusicher\": occurrences=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess - check word stems behind IDs from dictionary\n",
    "\n",
    "bow_doc = bow_corpus[0]\n",
    "\n",
    "for i in tqdm(range(len(bow_doc))):\n",
    "    print(f\"Key {bow_doc[i][0]} = \\\"{dictionary[bow_doc[i][0]]}\\\": occurrences={bow_doc[i][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e58443f3-e3e0-42ab-9d10-cfe8040871d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log lda algorithm\n",
    "import logging\n",
    "logging.basicConfig(filename = 'lda_model.log', filemode = 'w', force=True, format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# das gensim LDA Modul berichtet nicht automatisch über den Fortschritt des Algorithmus. Mit der logging-Bibliothek können wir log-files anlegen, die uns Auskunft über\n",
    "# das Modell und den Fortschritt des Algorithmus geben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0ccdf1c-cfa2-4de6-a659-694d9a867227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run LDA\n",
    "id2word = dictionary\n",
    "corpus = bow_corpus\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=10, # Anzahl der topics\n",
    "                                                random_state=100, # random state zum reproduzieren der Ergebnisse\n",
    "                                                chunksize=1000, # Anzahl Dokumente, die auf ein Mal in den Arbeitsspeicher geladen werden  \n",
    "                                                update_every=1, # Anzahl von chunks, die auf ein Mal bearbeitet werden. \n",
    "                                                eval_every=10, # Schätzung der log-perplexity (Maß für Modellgüte)\n",
    "                                                passes=10, # Anzahl wie häufig der Alg. durch den gesamten Datensatz geht\n",
    "                                                alpha='symmetric', # prior für die Dokumenten-Topic Verteilung\n",
    "                                                eta ='symmetric',  #  prior für die Topic-Wort Verteilung \n",
    "                                                iterations=100, # Anzahl der Iterationen\n",
    "                                                per_word_topics=True) #  Wenn auf True gesetzt berechnet das Modell auch eine Liste mit wahrscheinlichsten Topics für jedes Wort\n",
    "\n",
    "# Um zu sehen, was gensim tut müssen wir in den log file schauen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "459c088b-2edc-4a16-8335-17d445144e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = 'lda_model.log', filemode = 'w', force=True, format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d7ce76e-69b8-4efd-aac7-fa692438108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.012*\"general\" + 0.011*\"trupp\" + 0.010*\"uns\" + 0.008*\"franzos\" + 0.008*\"arme\" + 0.007*\"feind\" + 0.007*\"hatt\" + 0.007*\"mann\" + 0.007*\"war\" + 0.006*\"regiment\"\n",
      "Topic: 1 \n",
      "Words: 0.015*\"acti\" + 0.012*\"uns\" + 0.011*\"bank\" + 0.011*\"thal\" + 0.010*\"neu\" + 0.009*\"loos\" + 0.008*\"juni\" + 0.008*\"jed\" + 0.008*\"herr\" + 0.008*\"thlr\"\n",
      "Topic: 2 \n",
      "Words: 0.017*\"anzeig\" + 0.015*\"vormittag\" + 0.015*\"konig\" + 0.011*\"termin\" + 0.011*\"marz\" + 0.011*\"uns\" + 0.010*\"morg\" + 0.009*\"mach\" + 0.009*\"tod\" + 0.008*\"februar\"\n",
      "Topic: 3 \n",
      "Words: 0.010*\"hatt\" + 0.009*\"wenn\" + 0.009*\"mein\" + 0.008*\"schon\" + 0.008*\"ganz\" + 0.007*\"doch\" + 0.007*\"denn\" + 0.006*\"wied\" + 0.006*\"mehr\" + 0.006*\"war\"\n",
      "Topic: 4 \n",
      "Words: 0.029*\"deutsch\" + 0.016*\"krieg\" + 0.015*\"uns\" + 0.012*\"franzos\" + 0.009*\"preuss\" + 0.009*\"deutschland\" + 0.009*\"kais\" + 0.009*\"konig\" + 0.008*\"frankreich\" + 0.008*\"fried\"\n",
      "Topic: 5 \n",
      "Words: 0.033*\"paris\" + 0.010*\"thier\" + 0.007*\"versaill\" + 0.007*\"word\" + 0.007*\"hatt\" + 0.007*\"wied\" + 0.006*\"soll\" + 0.005*\"general\" + 0.005*\"mehr\" + 0.005*\"war\"\n",
      "Topic: 6 \n",
      "Words: 0.006*\"regier\" + 0.006*\"neu\" + 0.006*\"minist\" + 0.005*\"wenn\" + 0.005*\"soll\" + 0.004*\"word\" + 0.004*\"land\" + 0.004*\"graf\" + 0.004*\"mehr\" + 0.004*\"seit\"\n",
      "Topic: 7 \n",
      "Words: 0.009*\"koln\" + 0.008*\"gesucht\" + 0.007*\"gut\" + 0.005*\"thlr\" + 0.005*\"stell\" + 0.005*\"haus\" + 0.005*\"sucht\" + 0.004*\"franco\" + 0.004*\"lag\" + 0.004*\"neu\"\n",
      "Topic: 8 \n",
      "Words: 0.009*\"wenn\" + 0.008*\"jahr\" + 0.007*\"antrag\" + 0.006*\"staat\" + 0.006*\"soll\" + 0.005*\"haus\" + 0.005*\"regier\" + 0.005*\"weit\" + 0.005*\"frag\" + 0.005*\"ohn\"\n",
      "Topic: 9 \n",
      "Words: 0.009*\"jahr\" + 0.007*\"word\" + 0.006*\"hier\" + 0.005*\"tag\" + 0.005*\"seit\" + 0.004*\"erst\" + 0.004*\"stadt\" + 0.004*\"zeit\" + 0.004*\"herr\" + 0.004*\"einig\"\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model.print_topics(-1): # zeige Wortzusammensetzung der Topics, inkl. Gewichte (d.h. Bedeutung) einzelner Wörter\n",
    "    print(f\"Topic: {index} \\nWords: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799e35b6-24db-47fb-89ff-6071097b4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze topics - main topics for each document in the collection\n",
    "def analyse_topics(ldamodel, corpus, text):\n",
    "    main_topic = {}\n",
    "    percentage = {}\n",
    "    keywords = {}\n",
    "    text_snippets = {}\n",
    "    \n",
    "    for i, topic_list in enumerate(ldamodel [corpus]):\n",
    "        topic = topic_list[0]\n",
    "        topic = sorted(topic, key = lambda x: (x[1]), reverse = True) # extrahiert den wahrscheinlichsten Topicmix für jedes Dokument und sortiert die Topics. Ergebnis ist eine Liste\n",
    "        # mit Topic Id (topic_num) und Anteil des Topics am Dokument (prob_topic)\n",
    "       \n",
    "        for j, (topic_num, prop_topic) in enumerate(topic):\n",
    "            if j == 0: # extrahiere das wahrscheinlichste Topic, d.h. das mit dem größten Anteil\n",
    "                wp = ldamodel.show_topic(topic_num) # extrahiere topic keywords für das Topic mit dem größten Anteil\n",
    "                topic_keywords = \", \".join([word for word, prop in wp[:5]])\n",
    "                main_topic[i] = int(topic_num)\n",
    "                percentage[i] = round(prop_topic, 4)\n",
    "                keywords[i] = topic_keywords\n",
    "                text_snippets[i] = text[i][:8]\n",
    "            else:\n",
    "                break\n",
    "    return main_topic, percentage, keywords, text_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7bc4b19-036c-47ab-9aad-090f70e4abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topic, percentage, keywords, text_snippets = analyse_topics(lda_model, bow_corpus, processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fa866fa-aacb-4231-b09e-60115c032fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ID Main Topic Contribution (%) Keywords                            Snippet                                                                                   \n",
      " 0  7          0.7928           koln, gesucht, gut, thlr, stell\n",
      "    ['euit', 'chandlung', 'bach', 'drususgass', 'empfang', 'neu', 'mod', 'anzuleig']          \n",
      " 1  0          0.5035           general, trupp, uns, franzos, arme\n",
      " ['tekegrapliisci', 'depesch', 'versaill', 'offuciel', 'general', 'werd', 'griff', 'veind']\n",
      " 2  9          0.5011           jahr, word, hier, tag, seit\n",
      "        ['koln', 'loeal', 'nachricht', 'koln', 'auguft', 'iendurg', 'beraub', 'welch']            \n",
      " 3  9          0.5044           jahr, word, hier, tag, seit\n",
      "        ['nettung', 'schiffbruch', 'alt', 'hanla', 'schweht', 'segnend', 'aber', 'uns']           \n",
      " 4  7          0.4668           koln, gesucht, gut, thlr, stell\n",
      "    ['whit', 'broth', 'perlland', 'cement', 'cew', 'feuerf', 'stein', 'prima']                \n",
      " 5  9          0.4223           jahr, word, hier, tag, seit\n",
      "        ['grass', 'aber', 'war', 'bies', 'fehl', 'welch', 'uns', 'tag']                           \n",
      " 6  6          0.6072           regier, neu, minist, wenn, soll\n",
      "    ['kan', 'pfeis', 'tanzt', 'nicht', 'mehr', 'thun', 'ein', 'univ']                         \n",
      " 7  3          0.4956           hatt, wenn, mein, schon, ganz\n",
      "      ['wori', 'welch', 'fomiell', 'mund', 'gelegt', 'wann', 'fahrt', 'floquet']                \n",
      " 8  9          0.6275           jahr, word, hier, tag, seit\n",
      "        ['deng', 'onudrutfuss', 'abztret', 'terrain', 'wird', 'dageg', 'abgelett', 'wuehreud']    \n",
      " 9  9          0.4914           jahr, word, hier, tag, seit\n",
      "        ['vaterlund', 'fraucn', 'vercin', 'koln', 'unt', 'bezugnatm', 'unf', 'vorgestr']          \n"
     ]
    }
   ],
   "source": [
    "# analyze topics - print out main topic for each document in the collection\n",
    "\n",
    "indexes = []\n",
    "rows = []\n",
    "for i in range(0, 10):\n",
    "    indexes.append(i)\n",
    "rows.append(['ID', 'Main Topic', 'Contribution (%)', 'Keywords', 'Snippet' ])\n",
    "\n",
    "for idx in indexes:\n",
    "    rows.append([str(idx), f\"{main_topic.get(idx)}\",\n",
    "                f\"{percentage.get(idx):.4f}\",\n",
    "                f\"{keywords.get(idx)}\\n\",\n",
    "                f\"{text_snippets.get(idx)}\"])\n",
    "columns = zip(*rows)\n",
    "column_width = [max(len(item) for item in col) for col in columns]\n",
    "for row in rows:\n",
    "    print(''.join(' {:{width}}'.format(row[i], width=column_width[i]) for i in range(0, len(row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "786870aa-6a26-4005-8afd-2da46e4e75e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# analyze topics - visualize with pyLDAvis\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "#pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary=lda_model.id2word, sort_topics=False)\n",
    "#vis\n",
    "pyLDAvis.save_html(vis, 'lda.html')\n",
    "print(vis.topic_order)\n",
    "# Achtung pyLDAvis ordnet die per default Topics nach Anteil der token im Korpus. Die Nummerierung der Topics aus den vorherhigen Schritten stimmt daher nicht mir der Nummerierung der Topics\n",
    "# in der pyLDAvis Visualisierung überein! Indem wir sort_topics auf False setzen übernehmen wir die Sortierung des gensim LDA Models, allerdings beginnt gensim die Zählung bei 0\n",
    "# und pyLDAvis bei 1. \n",
    "# https://github.com/bmabey/pyLDAvis/issues/127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a61cdfe3-4347-40a0-860e-bfd22d0b4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lda_model.get_document_topics(corpus[0], minimum_probability=None, minimum_phi_value=None, per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17df580a-69f7-400a-a06c-6c722db7c640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.035502817), (5, 0.024693564), (7, 0.79282206), (9, 0.14302818)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
